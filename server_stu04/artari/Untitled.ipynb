{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA/FJREFUeJzt3bFtE2EYgGEfokZMQEXBCBEDRC5YhkzABBkDMQBFREGJMgyiQIgiBUdvKcTJe+S/c56ndn5/zesvPuUu0zzPO+Dhno0eALZORBCJCCIRQSQiiEQEkYggEhFEIoLo+egBdrvdbpomfzbB6szzPB3zOpsIIhFBJCKIRATRKi4srNHl5eW9f+bi4iKdcfjzS51RrWGGQ4czPcZ73sYmgsgmOtL/2BIjtt1D3PUp/xgzrJlNBJFNxL099c1zyCaCyCbi3kZ8L1szmwgim+hIS3zaruWMLbznlthEEIkIomkNT0B1PxFr5H4ieCSruLDgiytbZhNBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigmgVt0LcZeRzljldS92CYxNBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBtIknoF7v96NH4AR9W+gcmwgiEUEkIohEBJGIINrE1bk/r3+OHgFuZRNBJCKIRASRiCASEUQigmgTl7h/vPg9egS4lU0EkYggEhFEIoJIRBBt4+rcm5vRI3CKvi9zjE0EkYggEhFEIoJIRBBt4urcxz+vRo/ACTpf6BybCCIRQSQiiEQEkYgg2sTVuZtPH0aPwCk6X+afq9hEEIkIIhFBJCKIRASRiCDaxCXur1dno0fgBL07v1zkHJsIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCJudb3f7673+9FjrJ6IIBIRRCKC6PnoAVivs6ur0SNsgk0EkYggEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEq3jGwueXv0aPQLTE8+ke+5kOb798+fcL3r8/6hybCCIRQSQiiFbxnYjte8rPqLOJILKJeLLu2p7zkedM83zsS/+faZrGDwEH5nmejnmdX+cgEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEIoJIRBCJCCIRQbSKWyFgy2wiiEQEkYggEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEIoJIRBCJCKK/Bx1mHvvCKZoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe26f89efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA/FJREFUeJzt3bFtE2EYgGEfokZMQEXBCBEDRC5YhkzABBkDMQBFREGJMgyiQIgiBUdvKcTJe+S/c56ndn5/zesvPuUu0zzPO+Dhno0eALZORBCJCCIRQSQiiEQEkYggEhFEIoLo+egBdrvdbpomfzbB6szzPB3zOpsIIhFBJCKIRATRKi4srNHl5eW9f+bi4iKdcfjzS51RrWGGQ4czPcZ73sYmgsgmOtL/2BIjtt1D3PUp/xgzrJlNBJFNxL099c1zyCaCyCbi3kZ8L1szmwgim+hIS3zaruWMLbznlthEEIkIomkNT0B1PxFr5H4ieCSruLDgiytbZhNBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigmgVt0LcZeRzljldS92CYxNBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBtIknoF7v96NH4AR9W+gcmwgiEUEkIohEBJGIINrE1bk/r3+OHgFuZRNBJCKIRASRiCASEUQigmgTl7h/vPg9egS4lU0EkYggEhFEIoJIRBBt4+rcm5vRI3CKvi9zjE0EkYggEhFEIoJIRBBt4urcxz+vRo/ACTpf6BybCCIRQSQiiEQEkYgg2sTVuZtPH0aPwCk6X+afq9hEEIkIIhFBJCKIRASRiCDaxCXur1dno0fgBL07v1zkHJsIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCKIRASRiCASEUQigkhEEIkIIhFBJCJudb3f7673+9FjrJ6IIBIRRCKC6PnoAVivs6ur0SNsgk0EkYggEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEq3jGwueXv0aPQLTE8+ke+5kOb798+fcL3r8/6hybCCIRQSQiiFbxnYjte8rPqLOJILKJeLLu2p7zkedM83zsS/+faZrGDwEH5nmejnmdX+cgEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEIoJIRBCJCCIRQbSKWyFgy2wiiEQEkYggEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEIoJIRBCJCCIRQSQiiEQEkYggEhFEIoJIRBCJCKK/Bx1mHvvCKZoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe26f89efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "def show_state(env):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "#     plt.title(\"%s | Step: %d %s\" % (env._spec.id,step, info))\n",
    "    plt.axis('off')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "    \n",
    "env = gym.make('Breakout-v0')\n",
    "\n",
    "for _ in range(20):  \n",
    "    observation=env.reset()  \n",
    "    for t in range(100):  \n",
    "        show_state(env)\n",
    "        action=env.action_space.sample()  \n",
    "        observation,reward,done,info=env.step(action) \n",
    "        \n",
    "\n",
    "        if done:  \n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))  \n",
    "            break \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-3e396579d6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TF_CPP_MIN_LOG_LEVEL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m  \u001b[0;31m# OPENCV2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "import sys\n",
    "import cv2  # OPENCV2\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from gym import wrappers\n",
    "\n",
    "\n",
    "CNN_INPUT_WIDTH = 80\n",
    "CNN_INPUT_HEIGHT = 80\n",
    "CNN_INPUT_DEPTH = 1\n",
    "SERIES_LENGTH = 4\n",
    "\n",
    "REWARD_COFF = 3.0\n",
    "\n",
    "INITIAL_EPSILON = 1.0\n",
    "FINAL_EPSILON = 0.0001\n",
    "REPLAY_SIZE = 50000\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "OBSERVE_TIME = 500\n",
    "ENV_NAME = 'Breakout-v4'\n",
    "EPISODE = 100000\n",
    "STEP  = 1500\n",
    "TEST = 10\n",
    "\n",
    "\n",
    "class ImageProcess():\n",
    "    def ColorMat2B(self, state):   # this is the function used for the game flappy bird\n",
    "        height = 80\n",
    "        width = 80\n",
    "        state_gray = cv2.cvtColor( cv2.resize( state, ( height, width ) ) , cv2.COLOR_BGR2GRAY )\n",
    "        _,state_binary = cv2.threshold( state_gray, 5, 255, cv2.THRESH_BINARY )\n",
    "        state_binarySmall = cv2.resize( state_binary, ( width, height ))\n",
    "        cnn_inputImage = state_binarySmall.reshape( ( height, width ) )\n",
    "        return cnn_inputImage\n",
    "\n",
    "    def ColorMat2Binary(self, state):\n",
    "        # state_output = tf.image.rgb_to_grayscale(state_input)\n",
    "        # state_output = tf.image.crop_to_bounding_box(state_output, 34, 0, 160, 160)\n",
    "        # state_output = tf.image.resize_images(state_output, 80, 80, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        # state_output = tf.squeeze(state_output)\n",
    "        # return state_output\n",
    "\n",
    "        height = state.shape[0]\n",
    "        width = state.shape[1]\n",
    "        nchannel = state.shape[2]\n",
    "\n",
    "        sHeight = int(height * 0.5)\n",
    "        sWidth = CNN_INPUT_WIDTH\n",
    "\n",
    "        state_gray = cv2.cvtColor(state, cv2.COLOR_BGR2GRAY)\n",
    "        # print state_gray.shape\n",
    "        # cv2.imshow('test2', state_gray)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        _, state_binary = cv2.threshold(state_gray, 5, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        state_binarySmall = cv2.resize(state_binary, (sWidth, sHeight), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        cnn_inputImg = state_binarySmall[25:, :]\n",
    "        # rstArray = state_graySmall.reshape(sWidth * sHeight)\n",
    "        cnn_inputImg = cnn_inputImg.reshape((CNN_INPUT_WIDTH, CNN_INPUT_HEIGHT))\n",
    "        # print cnn_inputImg.shape\n",
    "\n",
    "        return cnn_inputImg\n",
    "\n",
    "    def ShowImageFromNdarray(self, state, p):\n",
    "        imgs = np.ndarray(shape=(4, 80, 80))\n",
    "\n",
    "        for i in range(0, 80):\n",
    "            for j in range(0, 80):\n",
    "                for k in range(0, 4):\n",
    "                    imgs[k][i][j] = state[i][j][k]\n",
    "\n",
    "        cv2.imshow(str(p + 1), imgs[0])\n",
    "        cv2.imshow(str(p + 2), imgs[1])\n",
    "        cv2.imshow(str(p + 3), imgs[2])\n",
    "        cv2.imshow(str(p + 4), imgs[3])\n",
    "\n",
    "\n",
    "class DQN():\n",
    "    def __init__(self, env):\n",
    "        self.imageProcess = ImageProcess()\n",
    "        self.epsilon = INITIAL_EPSILON\n",
    "        self.replay_buffer = deque()\n",
    "        self.recent_history_queue = deque()\n",
    "        self.action_dim = env.action_space.n\n",
    "        self.state_dim = CNN_INPUT_HEIGHT * CNN_INPUT_WIDTH\n",
    "        self.time_step = 0\n",
    "\n",
    "        self.session = tf.InteractiveSession()\n",
    "        self.create_network()\n",
    "        # self.create_training_method()\n",
    "        self.observe_time = 0\n",
    "\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.summary_writer = tf.summary.FileWriter('./path', self.session.graph)\n",
    "\n",
    "        self.session.run(tf.initialize_all_variables())\n",
    "\n",
    "    def create_network(self):\n",
    "\n",
    "        INPUT_DEPTH = SERIES_LENGTH\n",
    "\n",
    "        self.input_layer = tf.placeholder(tf.float32, [None, CNN_INPUT_WIDTH, CNN_INPUT_HEIGHT, INPUT_DEPTH],\n",
    "                                          name='status-input')\n",
    "        self.action_input = tf.placeholder(tf.float32, [None, self.action_dim])\n",
    "        self.y_input = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "        W1 = self.get_weights([8, 8, 4, 32])\n",
    "        b1 = self.get_bias([32])\n",
    "\n",
    "        h_conv1 = tf.nn.relu(tf.nn.conv2d(self.input_layer, W1, strides=[1, 4, 4, 1], padding='SAME') + b1)\n",
    "        conv1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        W2 = self.get_weights([4, 4, 32, 64])\n",
    "        b2 = self.get_bias([64])\n",
    "\n",
    "        h_conv2 = tf.nn.relu(tf.nn.conv2d(conv1, W2, strides=[1, 2, 2, 1], padding='SAME') + b2)\n",
    "        # conv2 = tf.nn.max_pool( h_conv2, ksize = [ 1, 2, 2, 1 ], strides= [ 1, 2, 2, 1 ], padding= 'SAME' )\n",
    "\n",
    "        W3 = self.get_weights([3, 3, 64, 64])\n",
    "        b3 = self.get_bias([64])\n",
    "\n",
    "        h_conv3 = tf.nn.relu(tf.nn.conv2d(h_conv2, W3, strides=[1, 1, 1, 1], padding='SAME') + b3)\n",
    "        # conv3 = tf.nn.max_pool( h_conv3, ksize= [ 1,2,2,1], strides=[ 1,2,2,1 ],padding= 'SAME' )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_fc1 = self.get_weights([1600, 512])\n",
    "        b_fc1 = self.get_bias([512])\n",
    "\n",
    "        # h_conv2_flat = tf.reshape( h_conv2, [ -1, 11 * 11 * 32 ] )\n",
    "        conv3_flat = tf.reshape(h_conv3, [-1, 1600])\n",
    "\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(conv3_flat, W_fc1) + b_fc1)\n",
    "\n",
    "        W_fc2 = self.get_weights([512, self.action_dim])\n",
    "        b_fc2 = self.get_bias([self.action_dim])\n",
    "\n",
    "        self.Q_value = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "        Q_action = tf.reduce_sum(tf.multiply(self.Q_value, self.action_input), reduction_indices=1)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.y_input - Q_action))\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(1e-6).minimize(self.cost)\n",
    "\n",
    "    # def create_training_method(self):\n",
    "    #\n",
    "    #   # if len(self.recent_history_queue) > 4:\n",
    "    #   #   sess = tf.Session()\n",
    "    #   #   print sess.run(self.Q_value)\n",
    "    #   # global_step = tf.Variable(0, name='global_step', trainable=True)\n",
    "    #   # self.optimizer = tf.train.AdamOptimizer( 0.001 ).minimize( self.cost )\n",
    "\n",
    "    def train_network(self):\n",
    "        self.time_step += 1\n",
    "\n",
    "        minibatch = random.sample(self.replay_buffer, BATCH_SIZE)\n",
    "        state_batch = [data[0] for data in minibatch]\n",
    "        action_batch = [data[1] for data in minibatch]\n",
    "        reward_batch = [data[2] for data in minibatch]\n",
    "        next_state_batch = [data[3] for data in minibatch]\n",
    "        done_batch = [data[4] for data in minibatch]\n",
    "        # self.imageProcess.ShowImageFromNdarray( state_batch[0], 1 )\n",
    "\n",
    "        y_batch = []\n",
    "        Q_value_batch = self.Q_value.eval(feed_dict={self.input_layer: next_state_batch})\n",
    "\n",
    "        # print Q_value_batch\n",
    "        # print self.time_step\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        # print Q_value_batch.shape\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "\n",
    "            if done_batch[i]:\n",
    "                y_batch.append(reward_batch[i])\n",
    "            else:\n",
    "                y_batch.append(reward_batch[i] + GAMMA * np.max(Q_value_batch[i]))\n",
    "\n",
    "        self.optimizer.run(feed_dict={\n",
    "\n",
    "            self.input_layer: state_batch,\n",
    "            self.action_input: action_batch,\n",
    "            self.y_input: y_batch\n",
    "\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def percieve(self, state_shadow, action_index, reward, state_shadow_next, done, episode):\n",
    "\n",
    "        action = np.zeros( self.action_dim )\n",
    "        action[ action_index ] = 1\n",
    "\n",
    "        self.replay_buffer.append([state_shadow, action, reward, state_shadow_next, done])\n",
    "\n",
    "        self.observe_time += 1\n",
    "        if self.observe_time % 1000 and self.observe_time <= OBSERVE_TIME == 0:\n",
    "            print(self.observe_time)\n",
    "\n",
    "        if len(self.replay_buffer) > REPLAY_SIZE:\n",
    "            self.replay_buffer.popleft()\n",
    "\n",
    "        if len(self.replay_buffer) > BATCH_SIZE and self.observe_time > OBSERVE_TIME:\n",
    "            self.train_network()\n",
    "\n",
    "    def get_greedy_action(self, state_shadow):\n",
    "\n",
    "        rst = self.Q_value.eval(feed_dict={self.input_layer: [state_shadow]})[0]\n",
    "        # print rst\n",
    "        print(np.max( rst ))\n",
    "        return np.argmax(rst)\n",
    "\n",
    "    def get_action(self, state_shadow):\n",
    "        if self.epsilon >= FINAL_EPSILON and self.observe_time > OBSERVE_TIME:\n",
    "            self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000\n",
    "\n",
    "        action = np.zeros(self.action_dim)\n",
    "        action_index = None\n",
    "        if random.random() < self.epsilon:\n",
    "            action_index = random.randint(0, self.action_dim - 1)\n",
    "        else:\n",
    "            action_index = self.get_greedy_action(state_shadow)\n",
    "\n",
    "        return action_index\n",
    "\n",
    "\n",
    "    def get_weights(self, shape):\n",
    "        weight = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(weight)\n",
    "\n",
    "    def get_bias(self, shape):\n",
    "        bias = tf.constant(0.01, shape=shape)\n",
    "        return tf.Variable(bias)\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make(ENV_NAME)\n",
    "    #env = wrappers.Monitor(env,'/home/users/cc/wkspc/artari/video',force=True)\n",
    "    state_shadow = None\n",
    "    next_state_shadow = None\n",
    "\n",
    "\n",
    "    agent = DQN(env)\n",
    "    total_reward_decade = 0\n",
    "\n",
    "    # game_state = game.GameState()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for episode in range(EPISODE):\n",
    "\n",
    "        total_reward = 0\n",
    "        state = env.reset()\n",
    "        state = agent.imageProcess.ColorMat2Binary(state)  # now state is a binary image of 80 * 80\n",
    "        state_shadow = np.stack((state, state, state, state), axis=2)\n",
    "\n",
    "        for step in range(STEP):\n",
    "            env.render()\n",
    "            action = agent.get_action(state_shadow)\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            next_state = np.reshape( agent.imageProcess.ColorMat2Binary( next_state ), ( 80,80,1 ) )\n",
    "\n",
    "            # print next_state.shape\n",
    "            # print state_shadow.shape\n",
    "            next_state_shadow = np.append( next_state, state_shadow[ :,:,:3 ], axis= 2 )\n",
    "\n",
    "            total_reward += reward\n",
    "            agent.percieve(state_shadow, action, reward, next_state_shadow, done, episode)\n",
    "            state_shadow = next_state_shadow\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "        print('Episode:', episode, 'Total Point this Episode is:', total_reward)\n",
    "        total_reward_decade += total_reward\n",
    "        if episode % 10 == 0:\n",
    "            print('-------------')\n",
    "            print('Decade:', episode / 10, 'Total Reward in this Decade is:', total_reward_decade)\n",
    "            print('-------------')\n",
    "            total_reward_decade = 0\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
