{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "d67cc64e-8fb0-4178-b876-a852ed85f638"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "import sys\n",
    "import cv2  # OPENCV2\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from gym import wrappers\n",
    "\n",
    "\n",
    "CNN_INPUT_WIDTH = 80\n",
    "CNN_INPUT_HEIGHT = 80\n",
    "CNN_INPUT_DEPTH = 1\n",
    "SERIES_LENGTH = 4\n",
    "\n",
    "REWARD_COFF = 3.0\n",
    "\n",
    "INITIAL_EPSILON = 1.0\n",
    "FINAL_EPSILON = 0.0001\n",
    "REPLAY_SIZE = 50000\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "OBSERVE_TIME = 500\n",
    "ENV_NAME = 'Breakout-v0'\n",
    "EPISODE = 100000\n",
    "STEP  = 1500\n",
    "TEST = 10\n",
    "\n",
    "\n",
    "class ImageProcess():\n",
    "    def ColorMat2B(self, state):   # this is the function used for the game flappy bird\n",
    "        height = 80\n",
    "        width = 80\n",
    "        state_gray = cv2.cvtColor( cv2.resize( state, ( height, width ) ) , cv2.COLOR_BGR2GRAY )\n",
    "        _,state_binary = cv2.threshold( state_gray, 5, 255, cv2.THRESH_BINARY )\n",
    "        state_binarySmall = cv2.resize( state_binary, ( width, height ))\n",
    "        cnn_inputImage = state_binarySmall.reshape( ( height, width ) )\n",
    "        return cnn_inputImage\n",
    "\n",
    "    def ColorMat2Binary(self, state):\n",
    "        # state_output = tf.image.rgb_to_grayscale(state_input)\n",
    "        # state_output = tf.image.crop_to_bounding_box(state_output, 34, 0, 160, 160)\n",
    "        # state_output = tf.image.resize_images(state_output, 80, 80, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        # state_output = tf.squeeze(state_output)\n",
    "        # return state_output\n",
    "\n",
    "        height = state.shape[0]\n",
    "        width = state.shape[1]\n",
    "        nchannel = state.shape[2]\n",
    "\n",
    "        sHeight = int(height * 0.5)\n",
    "        sWidth = CNN_INPUT_WIDTH\n",
    "\n",
    "        state_gray = cv2.cvtColor(state, cv2.COLOR_BGR2GRAY)\n",
    "        # print state_gray.shape\n",
    "        # cv2.imshow('test2', state_gray)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        _, state_binary = cv2.threshold(state_gray, 5, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        state_binarySmall = cv2.resize(state_binary, (sWidth, sHeight), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        cnn_inputImg = state_binarySmall[25:, :]\n",
    "        # rstArray = state_graySmall.reshape(sWidth * sHeight)\n",
    "        cnn_inputImg = cnn_inputImg.reshape((CNN_INPUT_WIDTH, CNN_INPUT_HEIGHT))\n",
    "        # print cnn_inputImg.shape\n",
    "\n",
    "        return cnn_inputImg\n",
    "\n",
    "    def ShowImageFromNdarray(self, state, p):\n",
    "        imgs = np.ndarray(shape=(4, 80, 80))\n",
    "\n",
    "        for i in range(0, 80):\n",
    "            for j in range(0, 80):\n",
    "                for k in range(0, 4):\n",
    "                    imgs[k][i][j] = state[i][j][k]\n",
    "\n",
    "        cv2.imshow(str(p + 1), imgs[0])\n",
    "        cv2.imshow(str(p + 2), imgs[1])\n",
    "        cv2.imshow(str(p + 3), imgs[2])\n",
    "        cv2.imshow(str(p + 4), imgs[3])\n",
    "\n",
    "\n",
    "class DQN():\n",
    "    def __init__(self, env):\n",
    "        self.imageProcess = ImageProcess()\n",
    "        self.epsilon = INITIAL_EPSILON\n",
    "        self.replay_buffer = deque()\n",
    "        self.recent_history_queue = deque()\n",
    "        self.action_dim = env.action_space.n\n",
    "        self.state_dim = CNN_INPUT_HEIGHT * CNN_INPUT_WIDTH\n",
    "        self.time_step = 0\n",
    "\n",
    "        self.session = tf.InteractiveSession()\n",
    "        self.create_network()\n",
    "        # self.create_training_method()\n",
    "        self.observe_time = 0\n",
    "\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.summary_writer = tf.summary.FileWriter('./path', self.session.graph)\n",
    "\n",
    "        self.session.run(tf.initialize_all_variables())\n",
    "\n",
    "    def create_network(self):\n",
    "\n",
    "        INPUT_DEPTH = SERIES_LENGTH\n",
    "\n",
    "        self.input_layer = tf.placeholder(tf.float32, [None, CNN_INPUT_WIDTH, CNN_INPUT_HEIGHT, INPUT_DEPTH],\n",
    "                                          name='status-input')\n",
    "        self.action_input = tf.placeholder(tf.float32, [None, self.action_dim])\n",
    "        self.y_input = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "        W1 = self.get_weights([8, 8, 4, 32])\n",
    "        b1 = self.get_bias([32])\n",
    "\n",
    "        h_conv1 = tf.nn.relu(tf.nn.conv2d(self.input_layer, W1, strides=[1, 4, 4, 1], padding='SAME') + b1)\n",
    "        conv1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        W2 = self.get_weights([4, 4, 32, 64])\n",
    "        b2 = self.get_bias([64])\n",
    "\n",
    "        h_conv2 = tf.nn.relu(tf.nn.conv2d(conv1, W2, strides=[1, 2, 2, 1], padding='SAME') + b2)\n",
    "        # conv2 = tf.nn.max_pool( h_conv2, ksize = [ 1, 2, 2, 1 ], strides= [ 1, 2, 2, 1 ], padding= 'SAME' )\n",
    "\n",
    "        W3 = self.get_weights([3, 3, 64, 64])\n",
    "        b3 = self.get_bias([64])\n",
    "\n",
    "        h_conv3 = tf.nn.relu(tf.nn.conv2d(h_conv2, W3, strides=[1, 1, 1, 1], padding='SAME') + b3)\n",
    "        # conv3 = tf.nn.max_pool( h_conv3, ksize= [ 1,2,2,1], strides=[ 1,2,2,1 ],padding= 'SAME' )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        W_fc1 = self.get_weights([1600, 512])\n",
    "        b_fc1 = self.get_bias([512])\n",
    "\n",
    "        # h_conv2_flat = tf.reshape( h_conv2, [ -1, 11 * 11 * 32 ] )\n",
    "        conv3_flat = tf.reshape(h_conv3, [-1, 1600])\n",
    "\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(conv3_flat, W_fc1) + b_fc1)\n",
    "\n",
    "        W_fc2 = self.get_weights([512, self.action_dim])\n",
    "        b_fc2 = self.get_bias([self.action_dim])\n",
    "\n",
    "        self.Q_value = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "        Q_action = tf.reduce_sum(tf.multiply(self.Q_value, self.action_input), reduction_indices=1)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.y_input - Q_action))\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(1e-6).minimize(self.cost)\n",
    "\n",
    "    # def create_training_method(self):\n",
    "    #\n",
    "    #   # if len(self.recent_history_queue) > 4:\n",
    "    #   #   sess = tf.Session()\n",
    "    #   #   print sess.run(self.Q_value)\n",
    "    #   # global_step = tf.Variable(0, name='global_step', trainable=True)\n",
    "    #   # self.optimizer = tf.train.AdamOptimizer( 0.001 ).minimize( self.cost )\n",
    "\n",
    "    def train_network(self):\n",
    "        self.time_step += 1\n",
    "\n",
    "        minibatch = random.sample(self.replay_buffer, BATCH_SIZE)\n",
    "        state_batch = [data[0] for data in minibatch]\n",
    "        action_batch = [data[1] for data in minibatch]\n",
    "        reward_batch = [data[2] for data in minibatch]\n",
    "        next_state_batch = [data[3] for data in minibatch]\n",
    "        done_batch = [data[4] for data in minibatch]\n",
    "        # self.imageProcess.ShowImageFromNdarray( state_batch[0], 1 )\n",
    "\n",
    "        y_batch = []\n",
    "        Q_value_batch = self.Q_value.eval(feed_dict={self.input_layer: next_state_batch})\n",
    "\n",
    "        # print Q_value_batch\n",
    "        # print self.time_step\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        # print Q_value_batch.shape\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "\n",
    "            if done_batch[i]:\n",
    "                y_batch.append(reward_batch[i])\n",
    "            else:\n",
    "                y_batch.append(reward_batch[i] + GAMMA * np.max(Q_value_batch[i]))\n",
    "\n",
    "        self.optimizer.run(feed_dict={\n",
    "\n",
    "            self.input_layer: state_batch,\n",
    "            self.action_input: action_batch,\n",
    "            self.y_input: y_batch\n",
    "\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def percieve(self, state_shadow, action_index, reward, state_shadow_next, done, episode):\n",
    "\n",
    "        action = np.zeros( self.action_dim )\n",
    "        action[ action_index ] = 1\n",
    "\n",
    "        self.replay_buffer.append([state_shadow, action, reward, state_shadow_next, done])\n",
    "\n",
    "        self.observe_time += 1\n",
    "        if self.observe_time % 1000 and self.observe_time <= OBSERVE_TIME == 0:\n",
    "            print(self.observe_time)\n",
    "\n",
    "        if len(self.replay_buffer) > REPLAY_SIZE:\n",
    "            self.replay_buffer.popleft()\n",
    "\n",
    "        if len(self.replay_buffer) > BATCH_SIZE and self.observe_time > OBSERVE_TIME:\n",
    "            self.train_network()\n",
    "\n",
    "    def get_greedy_action(self, state_shadow):\n",
    "\n",
    "        rst = self.Q_value.eval(feed_dict={self.input_layer: [state_shadow]})[0]\n",
    "        # print rst\n",
    "        print(np.max( rst ))\n",
    "        return np.argmax(rst)\n",
    "\n",
    "    def get_action(self, state_shadow):\n",
    "        if self.epsilon >= FINAL_EPSILON and self.observe_time > OBSERVE_TIME:\n",
    "            self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000\n",
    "\n",
    "        action = np.zeros(self.action_dim)\n",
    "        action_index = None\n",
    "        if random.random() < self.epsilon:\n",
    "            action_index = random.randint(0, self.action_dim - 1)\n",
    "        else:\n",
    "            action_index = self.get_greedy_action(state_shadow)\n",
    "\n",
    "        return action_index\n",
    "\n",
    "\n",
    "    def get_weights(self, shape):\n",
    "        weight = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(weight)\n",
    "\n",
    "    def get_bias(self, shape):\n",
    "        bias = tf.constant(0.01, shape=shape)\n",
    "        return tf.Variable(bias)\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make(ENV_NAME)\n",
    "    env = wrappers.Monitor(env,'/home/users/cc/wkspc/artari/video',force=True)\n",
    "    state_shadow = None\n",
    "    next_state_shadow = None\n",
    "\n",
    "\n",
    "    agent = DQN(env)\n",
    "    total_reward_decade = 0\n",
    "\n",
    "    # game_state = game.GameState()\n",
    "    for episode in range(EPISODE):\n",
    "\n",
    "        total_reward = 0\n",
    "        state = env.reset()\n",
    "        state = agent.imageProcess.ColorMat2Binary(state)  # now state is a binary image of 80 * 80\n",
    "        state_shadow = np.stack((state, state, state, state), axis=2)\n",
    "\n",
    "        for step in range(STEP):\n",
    "#             env.render(mode='rgb_array')\n",
    "            action = agent.get_action(state_shadow)\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            next_state = np.reshape( agent.imageProcess.ColorMat2Binary( next_state ), ( 80,80,1 ) )\n",
    "\n",
    "            # print next_state.shape\n",
    "            # print state_shadow.shape\n",
    "            next_state_shadow = np.append( next_state, state_shadow[ :,:,:3 ], axis= 2 )\n",
    "\n",
    "            total_reward += reward\n",
    "            agent.percieve(state_shadow, action, reward, next_state_shadow, done, episode)\n",
    "            state_shadow = next_state_shadow\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "        with open('./cored1.txt', 'a', encoding='utf-8') as corefile:\n",
    "            corefile.writelines(['Episode:',str(episode), ' | Total Point this Episode is:',str(total_reward),'\\n'])\n",
    "        print('Episode:', episode, 'Total Point this Episode is:', total_reward)\n",
    "        total_reward_decade += total_reward\n",
    "        if episode % 10 == 0:\n",
    "            print('-------------')\n",
    "            print('Decade:', episode / 10, 'Total Reward in this Decade is:', total_reward_decade)\n",
    "            print('-------------')\n",
    "            total_reward_decade = 0\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "dfb3e29f-fae3-403f-a3c7-91dfeb485a34"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cc]",
   "language": "python",
   "name": "conda-env-cc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbpresent": {
   "slides": {
    "2af4cc38-9d41-4f0f-9b6a-96c388aec645": {
     "id": "2af4cc38-9d41-4f0f-9b6a-96c388aec645",
     "prev": null,
     "regions": {
      "f1a1e2c5-91bc-4619-affe-7ab657a79e45": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d67cc64e-8fb0-4178-b876-a852ed85f638",
        "part": "whole"
       },
       "id": "f1a1e2c5-91bc-4619-affe-7ab657a79e45"
      }
     }
    },
    "6957ecb7-27df-487f-8caa-1691bfe5025b": {
     "id": "6957ecb7-27df-487f-8caa-1691bfe5025b",
     "prev": "2af4cc38-9d41-4f0f-9b6a-96c388aec645",
     "regions": {
      "1a224f32-da66-40cc-bb0a-358e81b667da": {
       "attrs": {
        "height": 0.2,
        "width": 0.4,
        "x": 0.5,
        "y": 0.7
       },
       "id": "1a224f32-da66-40cc-bb0a-358e81b667da"
      },
      "2d6baa98-509e-4258-959f-10e12561f30f": {
       "attrs": {
        "height": 0.6,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "id": "2d6baa98-509e-4258-959f-10e12561f30f"
      },
      "37960fbc-1909-4d5d-a258-bf167a7072b7": {
       "attrs": {
        "height": 0.2,
        "width": 0.4,
        "x": 0.1,
        "y": 0.7
       },
       "id": "37960fbc-1909-4d5d-a258-bf167a7072b7"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
